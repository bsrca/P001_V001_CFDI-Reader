{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Libriaries\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandasgui as pg \n",
    "from sqlalchemy import create_engine\n",
    "import urllib\n",
    "import re\n",
    "import pyodbc \n",
    "#import pydash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful!\n"
     ]
    }
   ],
   "source": [
    "# Define the connection details\n",
    "server = 'jacobo-dev.database.windows.net'\n",
    "port = '1433'\n",
    "database = 'jacobo-dev-sqlserver-azure-001'\n",
    "username = 'azure-admin'\n",
    "password = 'ja-2023-un0ypzjo'\n",
    "driver = '{ODBC Driver 18 for SQL Server}'\n",
    "\n",
    "# Define the connection string\n",
    "conn_str = f\"DRIVER={driver};SERVER={server},{port};DATABASE={database};UID={username};PWD={password};Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30\"\n",
    "\n",
    "# Test SQL DB Connection\n",
    "try:\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    print(\"Connection successful!\")\n",
    "    conn.close()\n",
    "except pyodbc.Error as e:\n",
    "    print(\"Error connecting to database:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions\n",
    "\n",
    "def get_root(file_path):\n",
    "    \"\"\"Parse an XML file and return its root element.\"\"\"\n",
    "    xml_tree = ET.parse(file_path)\n",
    "    xml_root = xml_tree.getroot()\n",
    "    return xml_root\n",
    "\n",
    "\n",
    "def get_child_elements(xml_root):\n",
    "    # Create a list to store all child elements\n",
    "    elements = []\n",
    "    # Get all child elements of a given xml element\n",
    "    for child in xml_root:\n",
    "        elements.append(child)\n",
    "        elements.extend(get_child_elements(child))\n",
    "    #append xml root to elements list\n",
    "    #elements.append(xml_root)\n",
    "    return elements\n",
    "\n",
    "def get_attribute_cfdi(elements, tag_contains, attribute):\n",
    "    attribute_values = []\n",
    "    for element in elements:\n",
    "        cleaned_tag = re.sub(r\"{.*?}\", \"\", element.tag)\n",
    "        # Check if the element's tag contains the required text and then extract the attribute\n",
    "        if tag_contains in cleaned_tag:\n",
    "            attribute_value = element.attrib.get(attribute)\n",
    "            if attribute_value is not None:\n",
    "                attribute_values.append(attribute_value)\n",
    "    values = ', '.join(attribute_values)      \n",
    "    return values\n",
    "#print(get_attribute_cfdi(elements, 'TimbreFiscalDigital', 'UUID'))\n",
    "#print(get_attribute_cfdi(elements, 'Receptor', 'Rfc'))\n",
    "\n",
    "\n",
    "def pascal_case(text):\n",
    "    return ''.join(word.capitalize() for word in text.split())\n",
    "\n",
    "\n",
    "def get_xml_metadata(elements):\n",
    "\n",
    "    # Define a list to store row data\n",
    "    data = []\n",
    "\n",
    "    # Define a dictionary for the attribute field counters\n",
    "    field_counters = {}\n",
    "\n",
    "    # Get UUID from 'TimbreFiscalDigital' element\n",
    "    uuid = get_attribute_cfdi(elements, 'TimbreFiscalDigital', 'UUID')\n",
    "    \n",
    "    # Iterate over elements\n",
    "    for element in elements:\n",
    "        if element.attrib:\n",
    "            cleaned_tag = pascal_case(re.sub(r\"{.*?}\", \"\", element.tag)).lower()\n",
    "            file_name = os.path.basename(xml_file_path)\n",
    "            file_path = xml_file_path\n",
    "\n",
    "            # If this tag has not been seen before, initialize its counter\n",
    "            if element.tag not in field_counters:\n",
    "                field_counters[element.tag] = 1\n",
    "\n",
    "            # Iterate over attributes of the element\n",
    "            for key, value in element.attrib.items():\n",
    "                cleaned_key = pascal_case(re.sub(r\"{.*?}\", \"\", key)).lower()\n",
    "                # Add the data to the list, including the current attribute field number\n",
    "                data.append({'field_number': field_counters[element.tag], 'file_path': file_path, 'file_name': file_name, 'cleaned_tag': cleaned_tag, 'tag': element.tag, 'key': key, 'cleaned_key': cleaned_key,'value': value, 'UUID': uuid})\n",
    "\n",
    "            # Increment the counter for this attribute field\n",
    "            field_counters[element.tag] += 1\n",
    "\n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Return the DataFrame\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_unique_tags(elements):\n",
    "    # Define a list to store tag names\n",
    "    tag_list = []\n",
    "\n",
    "    for element in elements:\n",
    "        # If the attribute dictionary is not empty, add the tag to the list\n",
    "        if element.attrib:\n",
    "            tag_list.append(element.tag)\n",
    "\n",
    "    # Convert the list to a set to get unique tags, then convert it back to a list\n",
    "    tag_list = list(set(tag_list))\n",
    "    \n",
    "    return tag_list\n",
    "\n",
    "\n",
    "def create_dataframes(elements, tag_list, metadata_df):\n",
    "    # Create an empty dictionary to hold the dataframes\n",
    "    cfdi_df = {}\n",
    "\n",
    "    # key fields\n",
    "    uuid = get_attribute_cfdi(elements, 'TimbreFiscalDigital', 'UUID')\n",
    "    emisor_rfc = get_attribute_cfdi(elements, 'Emisor', 'Rfc')\n",
    "    receptor_rfc = get_attribute_cfdi(elements, 'Receptor', 'Rfc')\n",
    "    comprobante_tipo = get_attribute_cfdi(elements, 'Comprobante', 'TipoDeComprobante')\n",
    "\n",
    "    for tag in tag_list:\n",
    "        # Filter the DataFrame\n",
    "        filtered_df = metadata_df[metadata_df['tag'] == tag]\n",
    "\n",
    "        # Custom aggregation function to concatenate values into a list\n",
    "        aggfunc = lambda x: list(x) if len(x) > 1 else np.max(x)\n",
    "\n",
    "        # Create a pivot table\n",
    "        pivot_table = pd.pivot_table(filtered_df, values='value', index=['field_number'], columns=['cleaned_key'], aggfunc=aggfunc)\n",
    "\n",
    "        # Reset index and change the column names\n",
    "        df = pivot_table.reset_index().rename_axis(None, axis=1)\n",
    "\n",
    "        # Add the UUID as a new column to the DataFrame\n",
    "        df['uuid'] = uuid\n",
    "        df['emisor_rfc'] = emisor_rfc\n",
    "        df['receptor_rfc'] = receptor_rfc\n",
    "        df['comprobante_tipo'] = comprobante_tipo\n",
    "\n",
    "        cfdi_df[tag] = df\n",
    "        \n",
    "    return cfdi_df\n",
    "\n",
    "\n",
    "# Function to create a connection engine\n",
    "def create_db_engine(driver, server, port, database, username, password):\n",
    "    params = urllib.parse.quote_plus(\n",
    "        f'DRIVER={driver};SERVER={server},{port};DATABASE={database};UID={username};PWD={password}'\n",
    "    )\n",
    "    engine = create_engine(f'mssql+pyodbc:///?odbc_connect={params}')\n",
    "    return engine\n",
    "\n",
    "\n",
    "# Function to write a DataFrame to a SQL table\n",
    "def write_to_db(df_dict, engine):\n",
    "    for tag, df in df_dict.items():\n",
    "        cleaned_tag = re.sub(r\"{.*?}\", \"\", tag)\n",
    "        table_name = 'cfdi_' + cleaned_tag\n",
    "        df.to_sql(table_name, engine, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the XML file path\n",
    "xml_file_path = r\"C:\\Users\\Roberto\\OneDrive\\cargoIabono\\Proyectos y Desarrollos\\P001_V001_CFDI-Reader\\01_Inputs\\Facturas\\0F23FE0D-8324-4BCE-AFAC-68CB67E89714.xml\"\n",
    "\n",
    "# Another XML file path for future use\n",
    "# xml_file_path = r\"C:\\Users\\Roberto\\OneDrive\\cargoIabono\\Proyectos y Desarrollos\\P001_V001_CFDI-Reader\\01_Inputs\\Nomina\\EMS2103108P3_Pago de n√≥mina_20220815_N_AOAR951019842.xml\"\n",
    "\n",
    "# Parse the XML file and get its root element\n",
    "xml_root = get_root(xml_file_path)\n",
    "\n",
    "# Get all child elements of the root element\n",
    "elements = get_child_elements(xml_root)\n",
    "\n",
    "# Append the root element to the list of child elements\n",
    "elements.append(xml_root)\n",
    "\n",
    "# Extract metadata from the elements and convert it into a pandas DataFrame\n",
    "metadata_df = get_xml_metadata(elements)\n",
    "\n",
    "# Extract unique tags from the elements\n",
    "tag_list = get_unique_tags(elements)\n",
    "\n",
    "# Create a dictionary of pandas DataFrames, each containing data for a unique tag\n",
    "cfdi_df = create_dataframes(elements, tag_list, metadata_df)\n",
    "\n",
    "# Create a connection engine for the SQL server\n",
    "engine = create_db_engine(driver, server, port, database, username, password)\n",
    "\n",
    "# Write each DataFrame in the dictionary to a separate SQL table\n",
    "write_to_db(cfdi_df, engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{http://www.sat.gob.mx/cfd/3}Emisor', '{http://www.sat.gob.mx/cfd/3}Receptor', '{http://www.sat.gob.mx/Pagos}DoctoRelacionado', '{http://www.sat.gob.mx/Pagos}Pago', '{http://www.sat.gob.mx/Pagos}Pagos', '{http://www.sat.gob.mx/cfd/3}Concepto', '{http://www.sat.gob.mx/cfd/3}Comprobante', '{http://www.sat.gob.mx/TimbreFiscalDigital}TimbreFiscalDigital']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field_number</th>\n",
       "      <th>nombre</th>\n",
       "      <th>rfc</th>\n",
       "      <th>usocfdi</th>\n",
       "      <th>uuid</th>\n",
       "      <th>emisor_rfc</th>\n",
       "      <th>receptor_rfc</th>\n",
       "      <th>comprobante_tipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>GENVAMEX, S.A. DE C.V. AV. NOGALAR SUR No. 301</td>\n",
       "      <td>FAN540305I15</td>\n",
       "      <td>P01</td>\n",
       "      <td>0F23FE0D-8324-4BCE-AFAC-68CB67E89714</td>\n",
       "      <td>FIS780810KQ9</td>\n",
       "      <td>FAN540305I15</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   field_number                                          nombre           rfc  \\\n",
       "0             1  GENVAMEX, S.A. DE C.V. AV. NOGALAR SUR No. 301  FAN540305I15   \n",
       "\n",
       "  usocfdi                                  uuid    emisor_rfc  receptor_rfc  \\\n",
       "0     P01  0F23FE0D-8324-4BCE-AFAC-68CB67E89714  FIS780810KQ9  FAN540305I15   \n",
       "\n",
       "  comprobante_tipo  \n",
       "0                P  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tag_list)\n",
    "cfdi_df['{http://www.sat.gob.mx/cfd/3}Receptor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def get_xml_files(directory, include_subdirectories=False):\n",
    "    # Define the file pattern\n",
    "    pattern = '**/*.xml' if include_subdirectories else '*.xml'\n",
    "\n",
    "    # Get the list of all XML files in the directory and its subdirectories\n",
    "    xml_files = glob.glob(os.path.join(directory, pattern), recursive=True)\n",
    "\n",
    "    return xml_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto\\OneDrive\\cargoIabono\\Proyectos y Desarrollos\\P001_V001_CFDI-Reader\\01_Inputs\\Facturas\\01DAD1D3-CA8F-4F0D-8CA7-E0347D111EC4.xml\n",
      "C:\\Users\\Roberto\\OneDrive\\cargoIabono\\Proyectos y Desarrollos\\P001_V001_CFDI-Reader\\01_Inputs\\Facturas\\0A8BEAE0-F410-4A97-8860-7F5EBADC0D60.xml\n",
      "C:\\Users\\Roberto\\OneDrive\\cargoIabono\\Proyectos y Desarrollos\\P001_V001_CFDI-Reader\\01_Inputs\\Facturas\\0C58F816-7800-44E2-96FF-631A8E432C50.xml\n",
      "C:\\Users\\Roberto\\OneDrive\\cargoIabono\\Proyectos y Desarrollos\\P001_V001_CFDI-Reader\\01_Inputs\\Facturas\\0D0E1EBB-003E-4F17-B2BE-0A5442819D1C.xml\n",
      "C:\\Users\\Roberto\\OneDrive\\cargoIabono\\Proyectos y Desarrollos\\P001_V001_CFDI-Reader\\01_Inputs\\Facturas\\0F23FE0D-8324-4BCE-AFAC-68CB67E89714.xml\n",
      "C:\\Users\\Roberto\\OneDrive\\cargoIabono\\Proyectos y Desarrollos\\P001_V001_CFDI-Reader\\01_Inputs\\Facturas\\1F8FA056-C516-4349-8E87-DC2EC8F831D5.xml\n",
      "C:\\Users\\Roberto\\OneDrive\\cargoIabono\\Proyectos y Desarrollos\\P001_V001_CFDI-Reader\\01_Inputs\\Nomina\\EMS2103108P3_Pago de n√≥mina_20220815_N_AOAR951019842.xml\n"
     ]
    }
   ],
   "source": [
    "directory = r\"C:\\Users\\Roberto\\OneDrive\\cargoIabono\\Proyectos y Desarrollos\\P001_V001_CFDI-Reader\\01_Inputs\"\n",
    "xml_files = get_xml_files(directory, include_subdirectories=True)\n",
    "for xml_file in xml_files:\n",
    "    print(xml_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "(pyodbc.ProgrammingError) ('42S22', \"[42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Invalid column name 'unidad'. (207) (SQLExecDirectW); [42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Statement(s) could not be prepared. (8180)\")\n[SQL: INSERT INTO [cfdi_Concepto] (field_number, cantidad, claveprodserv, claveunidad, descripcion, importe, unidad, valorunitario, uuid, emisor_rfc, receptor_rfc, comprobante_tipo) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)]\n[parameters: (1, '24245', '73121601', 'KGM', 'BO920', '28609.10', 'KG', '1.18', '01DAD1D3-CA8F-4F0D-8CA7-E0347D111EC4', 'FIS780810KQ9', 'MES880922JQA', 'I')]\n(Background on this error at: https://sqlalche.me/e/20/f405)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Roberto\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1964\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1963\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1964\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[0;32m   1965\u001b[0m             cursor, str_statement, effective_parameters, context\n\u001b[0;32m   1966\u001b[0m         )\n\u001b[0;32m   1968\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n",
      "File \u001b[1;32mc:\\Users\\Roberto\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\default.py:748\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 748\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(statement, parameters)\n",
      "\u001b[1;31mProgrammingError\u001b[0m: ('42S22', \"[42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Invalid column name 'unidad'. (207) (SQLExecDirectW); [42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Statement(s) could not be prepared. (8180)\")",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Roberto\\OneDrive\\cargoIabono\\Proyectos y Desarrollos\\P001_V001_CFDI-Reader\\02_Process\\multi_cfdi_to_sql_V001.ipynb Cell 8\u001b[0m in \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Roberto/OneDrive/cargoIabono/Proyectos%20y%20Desarrollos/P001_V001_CFDI-Reader/02_Process/multi_cfdi_to_sql_V001.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m tag_list \u001b[39m=\u001b[39m get_unique_tags(elements)  \u001b[39m# Extract unique tags from the elements\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Roberto/OneDrive/cargoIabono/Proyectos%20y%20Desarrollos/P001_V001_CFDI-Reader/02_Process/multi_cfdi_to_sql_V001.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m cfdi_df \u001b[39m=\u001b[39m create_dataframes(elements, tag_list, metadata_df)  \u001b[39m# Create a dictionary of pandas DataFrames, each containing data for a unique tag\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Roberto/OneDrive/cargoIabono/Proyectos%20y%20Desarrollos/P001_V001_CFDI-Reader/02_Process/multi_cfdi_to_sql_V001.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m write_to_db(cfdi_df, engine)  \u001b[39m# Write each DataFrame in the dictionary to a separate SQL table\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Roberto/OneDrive/cargoIabono/Proyectos%20y%20Desarrollos/P001_V001_CFDI-Reader/02_Process/multi_cfdi_to_sql_V001.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFile Uploaded: \u001b[39m\u001b[39m\"\u001b[39m, xml_file)\n",
      "\u001b[1;32mc:\\Users\\Roberto\\OneDrive\\cargoIabono\\Proyectos y Desarrollos\\P001_V001_CFDI-Reader\\02_Process\\multi_cfdi_to_sql_V001.ipynb Cell 8\u001b[0m in \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Roberto/OneDrive/cargoIabono/Proyectos%20y%20Desarrollos/P001_V001_CFDI-Reader/02_Process/multi_cfdi_to_sql_V001.ipynb#X12sZmlsZQ%3D%3D?line=138'>139</a>\u001b[0m cleaned_tag \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39m\u001b[39m.*?}\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, tag)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Roberto/OneDrive/cargoIabono/Proyectos%20y%20Desarrollos/P001_V001_CFDI-Reader/02_Process/multi_cfdi_to_sql_V001.ipynb#X12sZmlsZQ%3D%3D?line=139'>140</a>\u001b[0m table_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcfdi_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m cleaned_tag\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Roberto/OneDrive/cargoIabono/Proyectos%20y%20Desarrollos/P001_V001_CFDI-Reader/02_Process/multi_cfdi_to_sql_V001.ipynb#X12sZmlsZQ%3D%3D?line=140'>141</a>\u001b[0m df\u001b[39m.\u001b[39;49mto_sql(table_name, engine, if_exists\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mappend\u001b[39;49m\u001b[39m'\u001b[39;49m, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\Roberto\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:2987\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2830\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2831\u001b[0m \u001b[39mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[0;32m   2832\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2983\u001b[0m \u001b[39m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[0;32m   2984\u001b[0m \u001b[39m\"\"\"\u001b[39;00m  \u001b[39m# noqa:E501\u001b[39;00m\n\u001b[0;32m   2985\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mimport\u001b[39;00m sql\n\u001b[1;32m-> 2987\u001b[0m \u001b[39mreturn\u001b[39;00m sql\u001b[39m.\u001b[39;49mto_sql(\n\u001b[0;32m   2988\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   2989\u001b[0m     name,\n\u001b[0;32m   2990\u001b[0m     con,\n\u001b[0;32m   2991\u001b[0m     schema\u001b[39m=\u001b[39;49mschema,\n\u001b[0;32m   2992\u001b[0m     if_exists\u001b[39m=\u001b[39;49mif_exists,\n\u001b[0;32m   2993\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   2994\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   2995\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   2996\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   2997\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[0;32m   2998\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Roberto\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\sql.py:695\u001b[0m, in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(frame, DataFrame):\n\u001b[0;32m    691\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    692\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m'\u001b[39m\u001b[39m argument should be either a Series or a DataFrame\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    693\u001b[0m     )\n\u001b[1;32m--> 695\u001b[0m \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39mto_sql(\n\u001b[0;32m    696\u001b[0m     frame,\n\u001b[0;32m    697\u001b[0m     name,\n\u001b[0;32m    698\u001b[0m     if_exists\u001b[39m=\u001b[39mif_exists,\n\u001b[0;32m    699\u001b[0m     index\u001b[39m=\u001b[39mindex,\n\u001b[0;32m    700\u001b[0m     index_label\u001b[39m=\u001b[39mindex_label,\n\u001b[0;32m    701\u001b[0m     schema\u001b[39m=\u001b[39mschema,\n\u001b[0;32m    702\u001b[0m     chunksize\u001b[39m=\u001b[39mchunksize,\n\u001b[0;32m    703\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m    704\u001b[0m     method\u001b[39m=\u001b[39mmethod,\n\u001b[0;32m    705\u001b[0m     engine\u001b[39m=\u001b[39mengine,\n\u001b[0;32m    706\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mengine_kwargs,\n\u001b[0;32m    707\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Roberto\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\sql.py:1738\u001b[0m, in \u001b[0;36mSQLDatabase.to_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m   1726\u001b[0m sql_engine \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[0;32m   1728\u001b[0m table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_table(\n\u001b[0;32m   1729\u001b[0m     frame\u001b[39m=\u001b[39mframe,\n\u001b[0;32m   1730\u001b[0m     name\u001b[39m=\u001b[39mname,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1735\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m   1736\u001b[0m )\n\u001b[1;32m-> 1738\u001b[0m total_inserted \u001b[39m=\u001b[39m sql_engine\u001b[39m.\u001b[39minsert_records(\n\u001b[0;32m   1739\u001b[0m     table\u001b[39m=\u001b[39mtable,\n\u001b[0;32m   1740\u001b[0m     con\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconnectable,\n\u001b[0;32m   1741\u001b[0m     frame\u001b[39m=\u001b[39mframe,\n\u001b[0;32m   1742\u001b[0m     name\u001b[39m=\u001b[39mname,\n\u001b[0;32m   1743\u001b[0m     index\u001b[39m=\u001b[39mindex,\n\u001b[0;32m   1744\u001b[0m     schema\u001b[39m=\u001b[39mschema,\n\u001b[0;32m   1745\u001b[0m     chunksize\u001b[39m=\u001b[39mchunksize,\n\u001b[0;32m   1746\u001b[0m     method\u001b[39m=\u001b[39mmethod,\n\u001b[0;32m   1747\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mengine_kwargs,\n\u001b[0;32m   1748\u001b[0m )\n\u001b[0;32m   1750\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_case_sensitive(name\u001b[39m=\u001b[39mname, schema\u001b[39m=\u001b[39mschema)\n\u001b[0;32m   1751\u001b[0m \u001b[39mreturn\u001b[39;00m total_inserted\n",
      "File \u001b[1;32mc:\\Users\\Roberto\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\sql.py:1335\u001b[0m, in \u001b[0;36mSQLAlchemyEngine.insert_records\u001b[1;34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39minf cannot be used with MySQL\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   1334\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1335\u001b[0m     \u001b[39mraise\u001b[39;00m err\n",
      "File \u001b[1;32mc:\\Users\\Roberto\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\sql.py:1325\u001b[0m, in \u001b[0;36mSQLAlchemyEngine.insert_records\u001b[1;34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msqlalchemy\u001b[39;00m \u001b[39mimport\u001b[39;00m exc\n\u001b[0;32m   1324\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1325\u001b[0m     \u001b[39mreturn\u001b[39;00m table\u001b[39m.\u001b[39;49minsert(chunksize\u001b[39m=\u001b[39;49mchunksize, method\u001b[39m=\u001b[39;49mmethod)\n\u001b[0;32m   1326\u001b[0m \u001b[39mexcept\u001b[39;00m exc\u001b[39m.\u001b[39mSQLAlchemyError \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m   1327\u001b[0m     \u001b[39m# GH34431\u001b[39;00m\n\u001b[0;32m   1328\u001b[0m     \u001b[39m# https://stackoverflow.com/a/67358288/6067848\u001b[39;00m\n\u001b[0;32m   1329\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m(1054, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown column \u001b[39m\u001b[39m'\u001b[39m\u001b[39minf(e0)?\u001b[39m\u001b[39m'\u001b[39m\u001b[39m in \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfield list\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m))(?#\u001b[39m\n\u001b[0;32m   1330\u001b[0m \u001b[39m    )|inf can not be used with MySQL\u001b[39m\u001b[39m\"\"\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Roberto\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\sql.py:946\u001b[0m, in \u001b[0;36mSQLTable.insert\u001b[1;34m(self, chunksize, method)\u001b[0m\n\u001b[0;32m    943\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    945\u001b[0m chunk_iter \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m(arr[start_i:end_i] \u001b[39mfor\u001b[39;00m arr \u001b[39min\u001b[39;00m data_list))\n\u001b[1;32m--> 946\u001b[0m num_inserted \u001b[39m=\u001b[39m exec_insert(conn, keys, chunk_iter)\n\u001b[0;32m    947\u001b[0m \u001b[39m# GH 46891\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39mif\u001b[39;00m is_integer(num_inserted):\n",
      "File \u001b[1;32mc:\\Users\\Roberto\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\sql.py:853\u001b[0m, in \u001b[0;36mSQLTable._execute_insert\u001b[1;34m(self, conn, keys, data_iter)\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \u001b[39mExecute SQL statement inserting data\u001b[39;00m\n\u001b[0;32m    843\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    850\u001b[0m \u001b[39m   Each item contains a list of values to be inserted\u001b[39;00m\n\u001b[0;32m    851\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    852\u001b[0m data \u001b[39m=\u001b[39m [\u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(keys, row)) \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m data_iter]\n\u001b[1;32m--> 853\u001b[0m result \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mexecute(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtable\u001b[39m.\u001b[39;49minsert(), data)\n\u001b[0;32m    854\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mrowcount\n",
      "File \u001b[1;32mc:\\Users\\Roberto\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1414\u001b[0m, in \u001b[0;36mConnection.execute\u001b[1;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[0;32m   1412\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mObjectNotExecutableError(statement) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   1413\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1414\u001b[0m     \u001b[39mreturn\u001b[39;00m meth(\n\u001b[0;32m   1415\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1416\u001b[0m         distilled_parameters,\n\u001b[0;32m   1417\u001b[0m         execution_options \u001b[39mor\u001b[39;49;00m NO_OPTIONS,\n\u001b[0;32m   1418\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Roberto\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\sql\\elements.py:486\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[1;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[39mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m    485\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, Executable)\n\u001b[1;32m--> 486\u001b[0m     \u001b[39mreturn\u001b[39;00m connection\u001b[39m.\u001b[39;49m_execute_clauseelement(\n\u001b[0;32m    487\u001b[0m         \u001b[39mself\u001b[39;49m, distilled_params, execution_options\n\u001b[0;32m    488\u001b[0m     )\n\u001b[0;32m    489\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mObjectNotExecutableError(\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Roberto\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1638\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[1;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[0;32m   1626\u001b[0m compiled_cache: Optional[CompiledCacheType] \u001b[39m=\u001b[39m execution_options\u001b[39m.\u001b[39mget(\n\u001b[0;32m   1627\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcompiled_cache\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_compiled_cache\n\u001b[0;32m   1628\u001b[0m )\n\u001b[0;32m   1630\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39m_compile_w_cache(\n\u001b[0;32m   1631\u001b[0m     dialect\u001b[39m=\u001b[39mdialect,\n\u001b[0;32m   1632\u001b[0m     compiled_cache\u001b[39m=\u001b[39mcompiled_cache,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1636\u001b[0m     linting\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\u001b[39m.\u001b[39mcompiler_linting \u001b[39m|\u001b[39m compiler\u001b[39m.\u001b[39mWARN_LINTING,\n\u001b[0;32m   1637\u001b[0m )\n\u001b[1;32m-> 1638\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_context(\n\u001b[0;32m   1639\u001b[0m     dialect,\n\u001b[0;32m   1640\u001b[0m     dialect\u001b[39m.\u001b[39;49mexecution_ctx_cls\u001b[39m.\u001b[39;49m_init_compiled,\n\u001b[0;32m   1641\u001b[0m     compiled_sql,\n\u001b[0;32m   1642\u001b[0m     distilled_parameters,\n\u001b[0;32m   1643\u001b[0m     execution_options,\n\u001b[0;32m   1644\u001b[0m     compiled_sql,\n\u001b[0;32m   1645\u001b[0m     distilled_parameters,\n\u001b[0;32m   1646\u001b[0m     elem,\n\u001b[0;32m   1647\u001b[0m     extracted_params,\n\u001b[0;32m   1648\u001b[0m     cache_hit\u001b[39m=\u001b[39;49mcache_hit,\n\u001b[0;32m   1649\u001b[0m )\n\u001b[0;32m   1650\u001b[0m \u001b[39mif\u001b[39;00m has_events:\n\u001b[0;32m   1651\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_execute(\n\u001b[0;32m   1652\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m   1653\u001b[0m         elem,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1657\u001b[0m         ret,\n\u001b[0;32m   1658\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Roberto\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1842\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1837\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exec_insertmany_context(\n\u001b[0;32m   1838\u001b[0m         dialect,\n\u001b[0;32m   1839\u001b[0m         context,\n\u001b[0;32m   1840\u001b[0m     )\n\u001b[0;32m   1841\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1842\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_exec_single_context(\n\u001b[0;32m   1843\u001b[0m         dialect, context, statement, parameters\n\u001b[0;32m   1844\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Roberto\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1983\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1980\u001b[0m     result \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39m_setup_result_proxy()\n\u001b[0;32m   1982\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m-> 1983\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_dbapi_exception(\n\u001b[0;32m   1984\u001b[0m         e, str_statement, effective_parameters, cursor, context\n\u001b[0;32m   1985\u001b[0m     )\n\u001b[0;32m   1987\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Roberto\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:2326\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[0;32m   2324\u001b[0m \u001b[39melif\u001b[39;00m should_wrap:\n\u001b[0;32m   2325\u001b[0m     \u001b[39massert\u001b[39;00m sqlalchemy_exception \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2326\u001b[0m     \u001b[39mraise\u001b[39;00m sqlalchemy_exception\u001b[39m.\u001b[39mwith_traceback(exc_info[\u001b[39m2\u001b[39m]) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m   2327\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2328\u001b[0m     \u001b[39massert\u001b[39;00m exc_info[\u001b[39m1\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Roberto\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1964\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1962\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m   1963\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1964\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[0;32m   1965\u001b[0m             cursor, str_statement, effective_parameters, context\n\u001b[0;32m   1966\u001b[0m         )\n\u001b[0;32m   1968\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n\u001b[0;32m   1969\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_cursor_execute(\n\u001b[0;32m   1970\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m   1971\u001b[0m         cursor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1975\u001b[0m         context\u001b[39m.\u001b[39mexecutemany,\n\u001b[0;32m   1976\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Roberto\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\default.py:748\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 748\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(statement, parameters)\n",
      "\u001b[1;31mProgrammingError\u001b[0m: (pyodbc.ProgrammingError) ('42S22', \"[42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Invalid column name 'unidad'. (207) (SQLExecDirectW); [42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Statement(s) could not be prepared. (8180)\")\n[SQL: INSERT INTO [cfdi_Concepto] (field_number, cantidad, claveprodserv, claveunidad, descripcion, importe, unidad, valorunitario, uuid, emisor_rfc, receptor_rfc, comprobante_tipo) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)]\n[parameters: (1, '24245', '73121601', 'KGM', 'BO920', '28609.10', 'KG', '1.18', '01DAD1D3-CA8F-4F0D-8CA7-E0347D111EC4', 'FIS780810KQ9', 'MES880922JQA', 'I')]\n(Background on this error at: https://sqlalche.me/e/20/f405)"
     ]
    }
   ],
   "source": [
    "# Create a connection engine for the SQL server outside the loop\n",
    "engine = create_db_engine(driver, server, port, database, username, password)\n",
    "\n",
    "for xml_file in xml_files:\n",
    "    xml_root = get_root(xml_file)  # Parse the XML file and get its root element\n",
    "    elements = get_child_elements(xml_root)  # Get all child elements of the root element\n",
    "    elements.append(xml_root)  # Append the root element to the list of child elements\n",
    "    metadata_df = get_xml_metadata(elements)  # Extract metadata from the elements and convert it into a pandas DataFrame\n",
    "    tag_list = get_unique_tags(elements)  # Extract unique tags from the elements\n",
    "    cfdi_df = create_dataframes(elements, tag_list, metadata_df)  # Create a dictionary of pandas DataFrames, each containing data for a unique tag\n",
    "    write_to_db(cfdi_df, engine)  # Write each DataFrame in the dictionary to a separate SQL table\n",
    "    print(\"File Uploaded: \", xml_file)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instrucciones**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  determinar el documto y armar loop basado en el tipo de cfdi y y la lista de archivos\n",
    "-  generar log de los archivos leidos, tipo de archivo, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (725445146.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn [29], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    var = get_attribute_cfdi(get_root(xml_file)), 'TimbreFiscalDigital', 'UUID')\u001b[0m\n\u001b[1;37m                                                                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "xml_file = r\"C:\\Users\\Roberto\\OneDrive\\cargoIabono\\Proyectos y Desarrollos\\P001_V001_CFDI-Reader\\01_Inputs\\Facturas\\0C58F816-7800-44E2-96FF-631A8E432C50.xml\"\n",
    "var = get_attribute_cfdi(get_root(xml_file)), 'TimbreFiscalDigital', 'UUID')\n",
    "uuidtemp = (get_attribute_cfdi(get_root(xml_file), 'TimbreFiscalDigital', 'UUID'))\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xml_file in xml_files:\n",
    "    xml_root = get_root(xml_file)  # Parse the XML file and get its root element\n",
    "    elements = get_child_elements(xml_root)  # Get all child elements of the root element\n",
    "    elements.append(xml_root)  # Append the root element to the list of child elements\n",
    "    \n",
    "    \n",
    "    #print(get_attribute_cfdi(xml_root, 'TimbreFiscalDigital', 'UUID'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
